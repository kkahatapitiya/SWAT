# Dataset / Model parameters
data_dir: /data/imagenet1K
dataset: ImageFolder
train_split: train
val_split: validation
model: vit_tiny_patch16_224 #vit_base_patch32_224 #(512) #vit_small_patch16_224 (192) #vit_tiny_patch16_224 (384)
pretrained: false
initial_checkpoint: ''
resume: ''
no_resume_opt: false
num_classes: 1000
gp: null
img_size: 224
input_size: null
crop_pct: 0.9
mean:
- 0.485
- 0.456
- 0.406
std:
- 0.229
- 0.224
- 0.225
interpolation: ''
batch_size: 256 #128 #256 #512 #768 #1024 #1024 #256 #512 #512 #512 #512 #4096 #224 ###     full 2048
validation_batch_size_multiplier: 1 #4

# Optimizer parameters
opt: adamw
opt_eps: 1.0e-06
opt_betas: null
momentum: 0.9
weight_decay: 0.3 #0.067 ###
clip_grad: 1.0
clip_mode: norm

# Learning rate schedule parameters
sched: cosine
lr: 0.75e-3 #0.375e-3 #0.5625e-3 #0.75e-3 #1.5e-3 #1.125e-3 #0.75e-3 #1.5e-3 #1.125e-3 #1.5e-3 #3.0e-3 #0.0008 ###
lr_noise: null
lr_noise_pct: 0.67
lr_noise_std: 1.0
lr_cycle_mul: 1.0
lr_cycle_limit: 1
warmup_lr: 1.0e-06
min_lr: 1.0e-05
epochs: 300 #600 ###
epoch_repeats: 0.0
start_epoch: null
decay_epochs: 1.0
warmup_epochs: 8 #8 #15 #12 #8 #15 #15 #12 #15 #30 #20 ### 10k steps?
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.988

# Augmentation & regularization parameters
no_aug: false
scale:
- 0.08
- 1.0
ratio:
- 0.67
- 1.5
hflip: 0.5
vflip: 0.0
color_jitter: 0.4
aa: rand-m15-n2-mstd1.0-inc1 #rand-m0-n0-mstd1.0-inc1 #rand-m15-n2-mstd1.0-inc1 #rand-m6-n4-mstd1.0-inc1 ###
aug_splits: 0
jsd: false
reprob: 0.0
remode: pixel
recount: 3
resplit: false
mixup: 0.5 #0.5 ###
cutmix: 1.0
cutmix_minmax: null
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
mixup_off_epoch: 0
smoothing: 0.1
train_interpolation: random
drop: 0. #0.1 #0. #0.1 #0.01 ###
drop_connect: null
drop_path: 0. #0.1 ###
drop_block: null

# Batch norm parameters (only works with gen_efficientnet based models currently)
bn_tf: false
bn_momentum: null
bn_eps: null
sync_bn: true #false ###
dist_bn: '' #reduce ###
split_bn: false

# Model Exponential Moving Average
model_ema: true
model_ema_force_cpu: false
model_ema_decay: 0.99992

# Misc
seed: 42
log_interval: 50
recovery_interval: 0
checkpoint_hist: 10
workers: 32 #16 #16 #4
save_images: false
amp: false
apex_amp: false #false ###
native_amp: true #false ###
channels_last: false
pin_mem: false
no_prefetcher: false
output: ''
experiment: ''
eval_metric: top1
tta: 0
local_rank: 0
use_multi_epochs_loader: true #false ###
torchscript: false
log_wandb: false
